---
title: "Lab 8"
author: "Julia Wilson"
date: "11/15/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Attach Packages
library(tidyverse)
library(broom)
library(stargazer)
library(modelsummary)
library(corrplot)
library(here)
```


## Read in data 
```{r}

homes <- read_csv(here("slo_homes.csv"))

```

A little bit of cleaning: 

Make a subset called homes_sub that only contains observations (rows) where the city is: 

- San Luis Obispo
- Arroyo Grande
- Atascadero
- Santa Maria-Orcutt

```{r}
# Filter for four cities 

homes_sub <- homes %>%
  filter(City %in% c("San Luis Obispo", "Arroyo Grande", "Atascadero", "Santa Maria-Orcutt"))
```

Check your wrangling! 
In Console: 
unique(homes_sub$City)

## Do a little exploring of our data 

Summary stats (home price, based on city and sale status): 

Find & return in a nice summary table the mean and sd or home price, grouped by city and sale status 

Notes: 
- Use na.rm if there is an na value in your data. 
- Include = FALSE or eval = FALSE
- In or Out of AES: if it's referring to a constant it should be outside of aes. If its referring to a variable it should be inside aes. 
- Alpha is used for transparency/translucent 
- To limit from 0 to 3 million (3e6): set limits

```{r, include = FALSE, eval = FALSE}
homes_sub %>% 
  group_by(City, Status) %>% 
  summarize(mean = mean(Price, na.rm = TRUE),
            sd = sd(Price, na.rm = TRUE)) 

# Actually I don't want to run this code... set eval = FALSE

# Data Visualization
ggplot(data = homes_sub, aes(x = Price)) + 
  geom_density(aes(color = City, fill = City), alpha = 0.3) + 
  scale_x_continuous(limits = c(0, 3e6))

```

Patterns noticed: 
Regular sales have higher prices than foreclosures and short sales 
SLO has higher mean prices than Arroyo Grande 
Just start looking at how values compare, and is it consistent? 

Explore the relationship (visual data exploration) between square footage & home price. Change the point COLOR by City, and the point shape by sale status. 

```{r}
ggplot(data = homes_sub, aes(x = SqFt, y = Price)) + 
  geom_point(aes(color = City, shape = Status)) +
  geom_smooth(method = lm)
```

## Model the relationship with home price as the dependent variable 

Saturated model: include every variable in the data set 

```{r}
homes_lm1 <- lm(Price ~ City + Bedrooms + SqFt + PricePerSqFt + Status, data = homes_sub)

# Make a subset that only contains quantitative variables 

homes_quant <- homes_sub %>% 
  select(Price:PricePerSqFt)

# Find correlation

homes_cor <- cor(homes_quant)
homes_cor

# Correlation Plot:
corrplot(homes_cor, method = "ellipse")

```

Bedrooms, bathrooms, sqft all tell you about the size of the house. 
Just looking at correlation between price, bedroom, bathroom, 

sqft & bathroom have a strong correlation
sqqft & price, moderately correlated 
bedrooms & bathrooms, moderately & positively correlated


View coefficients by typing homes_lm1 in the console -> 
Interpreting: for every additional bedroom, the price of the home will decrease by 23124 (which doesn't make sense, you have redundant variables)
Reference levels: Foreclosure & Arroyo Grande 

# How would I explore the diagnostic plots? 


```{r}
plot(homes_lm1)
```

Try another model where we simply this a bit: 

- City
- SqFt
- Status 

```{r}
homes_lm2 <- lm(Price ~ City + SqFt + Status, data = homes_sub) 
```

Model Fit: 
Higher R^2: 
84% of variance in home price is explained by the predictor variables in this model. (City, Sqft, Status) explains the variance. 

To get a higher value, you would need variables that don't exist here 
Adjusted R2: use with multiple linear regression bc it accounts for the fact that model fit will increase as an artifact of adding more variables
multiple r2: 

How to weight model fit, conceptual understanding, and model complexity 
- model fit vs complexity: use AIC (provides quant measure that provides comparison of balance between model fit & complexity)

Find the AIC value of each model: 

```{r}
AIC(homes_lm1)
AIC(homes_lm2)
```

Lower AIC implies a better balance of model fit and complexity 
In this case, you would use homes_lm1. However, you would still have major concerns because you know that there are unneeded variables

Maybe neither of these is what I am looking for. Maybe there is something in between? 

Try another permutation of this model that you think might make sense, check out & compare the model fit, outputs, and AIC value

```{r}
homes_lm3 <- lm(Price ~ City + Bedrooms + Status, data = homes_sub)
```

```{r}
AIC(homes_lm1)
AIC(homes_lm2)
AIC(homes_lm3)
```

Use `modelsummary` to show model outputs side-by-side: 


If you use model summary to return model outputs of multiple odels, it wants you to feed it to it as a list. 
```{r}
modelsummary(list(homes_lm1, homes_lm2, homes_lm3))
```

Couple ways to make predictions with our model 

## Start making predictions with this model

Use `broom::augment()`

```{r}
homes_predicted <- augment(homes_lm1)
```

Use the `predict()` function to try out your model on new scenarios that you create. 

# My Update!!

